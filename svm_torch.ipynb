{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a54ab091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Training new SVM model...\n",
      "Training...\n",
      "\n",
      "================= Model Performance =================\n",
      "üèãÔ∏è Training Accuracy  : 93.54%\n",
      "üß™ Validation Accuracy : 80.08%\n",
      "------------------------------------------------------\n",
      "üéØ Precision (weighted): 80.58%\n",
      "üìà Recall (weighted)   : 80.08%\n",
      "üî• F1-Score (weighted) : 80.17%\n",
      "======================================================\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry     0.8448    0.7967    0.8201       123\n",
      "     disgust     0.9048    0.8837    0.8941        86\n",
      "        fear     0.9062    0.8969    0.9016        97\n",
      "       happy     0.8053    0.6894    0.7429       132\n",
      "     neutral     0.8646    0.8557    0.8601        97\n",
      "          ps     0.6978    0.7886    0.7405       123\n",
      "         sad     0.7105    0.7642    0.7364       106\n",
      "        calm     0.6500    0.7647    0.7027        34\n",
      "\n",
      "    accuracy                         0.8008       798\n",
      "   macro avg     0.7980    0.8050    0.7998       798\n",
      "weighted avg     0.8058    0.8008    0.8017       798\n",
      "\n",
      "üíæ Model saved to svm_emotion_model.joblib\n",
      "Predicted Emotion: angry\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report\n",
    ")\n",
    "import joblib\n",
    "\n",
    "# =====================================================\n",
    "# FEATURE EXTRACTION\n",
    "# =====================================================\n",
    "def extract_features(file_path, max_pad_len=174):\n",
    "    signal, sr = librosa.load(file_path, sr=22050)\n",
    "    mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=40)\n",
    "    if mfcc.shape[1] < max_pad_len:\n",
    "        pad_width = max_pad_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_pad_len]\n",
    "    return mfcc\n",
    "\n",
    "# =====================================================\n",
    "# DATASET PREPARATION\n",
    "# =====================================================\n",
    "data_dirs = [\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\voice_data\\\\train_data\\\\SER\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive\\\\audio_speech_actors_01-24\\\\Actor_01\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive\\\\audio_speech_actors_01-24\\\\Actor_02\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive\\\\audio_speech_actors_01-24\\\\Actor_03\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive\\\\audio_speech_actors_01-24\\\\Actor_04\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive\\\\audio_speech_actors_01-24\\\\Actor_05\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive\\\\audio_speech_actors_01-24\\\\Actor_06\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive\\\\audio_speech_actors_01-24\\\\Actor_07\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive\\\\audio_speech_actors_01-24\\\\Actor_08\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive\\\\audio_speech_actors_01-24\\\\Actor_09\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive\\\\audio_speech_actors_01-24\\\\Actor_10\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive\\\\audio_speech_actors_01-24\\\\Actor_11\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive\\\\audio_speech_actors_01-24\\\\Actor_12\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive\\\\audio_speech_actors_01-24\\\\Actor_13\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive\\\\audio_speech_actors_01-24\\\\Actor_14\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive\\\\audio_speech_actors_01-24\\\\Actor_15\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive\\\\audio_speech_actors_01-24\\\\Actor_16\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive\\\\audio_speech_actors_01-24\\\\Actor_17\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive\\\\audio_speech_actors_01-24\\\\Actor_18\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive\\\\audio_speech_actors_01-24\\\\Actor_19\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive\\\\audio_speech_actors_01-24\\\\Actor_20\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive\\\\audio_speech_actors_01-24\\\\Actor_21\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive\\\\audio_speech_actors_01-24\\\\Actor_22\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive\\\\audio_speech_actors_01-24\\\\Actor_23\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive\\\\audio_speech_actors_01-24\\\\Actor_24\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive2\\\\Angry\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive2\\\\Happy\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive2\\\\Natural\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive2\\\\Sad\",\n",
    "    \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\archive2\\\\Surprised\"\n",
    "]\n",
    "\n",
    "X, y, emotions = [], [], []\n",
    "for data_dir in data_dirs:\n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"‚ö†Ô∏è Warning: {data_dir} not found, skipping...\")\n",
    "        continue\n",
    "    for file in os.listdir(data_dir):\n",
    "        if file.endswith(\".wav\"):\n",
    "            label = file.split(\"_\")[-1].replace(\".wav\", \"\")\n",
    "            if label not in emotions:\n",
    "                emotions.append(label)\n",
    "            path = os.path.join(data_dir, file)\n",
    "            mfcc = extract_features(path)\n",
    "            X.append(mfcc.flatten())\n",
    "            y.append(emotions.index(label))\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "if len(X) == 0:\n",
    "    raise RuntimeError(\"‚ùå No audio data found! Check dataset paths.\")\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# MODEL TRAINING / LOADING\n",
    "# =====================================================\n",
    "model_path = \"svm_emotion_model.joblib\"\n",
    "choice = input(\"Do you want to load the saved model? (yes/no): \").strip().lower()\n",
    "\n",
    "if choice == \"yes\" and os.path.exists(model_path):\n",
    "    print(\"üîÅ Loading saved SVM model...\")\n",
    "    model_data = joblib.load(model_path)\n",
    "    model = model_data[\"model\"]\n",
    "    emotions = model_data[\"emotions\"]\n",
    "else:\n",
    "    print(\"üß† Training new SVM model...\")\n",
    "\n",
    "    model = SVC(kernel=\"rbf\", C=10, gamma=\"scale\", probability=True)\n",
    "    print(\"Training...\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on training and validation sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    val_acc = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred, average=\"weighted\", zero_division=0)\n",
    "    recall = recall_score(y_val, y_val_pred, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(y_val, y_val_pred, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    print(\"\\n================= Model Performance =================\")\n",
    "    print(f\"üèãÔ∏è Training Accuracy  : {train_acc * 100:.2f}%\")\n",
    "    print(f\"üß™ Validation Accuracy : {val_acc * 100:.2f}%\")\n",
    "    print(\"------------------------------------------------------\")\n",
    "    print(f\"üéØ Precision (weighted): {precision * 100:.2f}%\")\n",
    "    print(f\"üìà Recall (weighted)   : {recall * 100:.2f}%\")\n",
    "    print(f\"üî• F1-Score (weighted) : {f1 * 100:.2f}%\")\n",
    "    print(\"======================================================\")\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_val, y_val_pred, target_names=emotions, digits=4))\n",
    "\n",
    "    joblib.dump({\"model\": model, \"emotions\": emotions}, model_path)\n",
    "    print(f\"üíæ Model saved to {model_path}\")\n",
    "\n",
    "# =====================================================\n",
    "# PREDICTION FUNCTION\n",
    "# =====================================================\n",
    "def predict_emotion(file_path):\n",
    "    mfcc = extract_features(file_path)\n",
    "    mfcc = mfcc.flatten().reshape(1, -1)\n",
    "    pred = model.predict(mfcc)[0]\n",
    "    return emotions[pred]\n",
    "\n",
    "# =====================================================\n",
    "# TEST PREDICTION\n",
    "# =====================================================\n",
    "test_file = \"K:\\\\Code\\\\Project\\\\Research Paper\\\\Emotion Detection\\\\voice_data\\\\test_data\\\\F_01_OISHI_S_2_SURPRISE_2.wav\"\n",
    "if os.path.exists(test_file):\n",
    "    print(\"Predicted Emotion:\", predict_emotion(test_file))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Test file not found:\", test_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
